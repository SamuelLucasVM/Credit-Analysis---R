---
title: "Crédito e Suas Relações"
author: "Samuel Lucas Vieira Matos, Marcus Paulo dos Santos Ferreira e Guilherme Silva Toledo"
format: html
number-sections: true
toc: true
toc-depth: 3
lang: pt
bibliography: refs/refs.bib
date: today
editor: visual
---

```{r Setup}
#| echo: true

# Setup para o relatório Quarto

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

```

# Introdução

Este relatório tem por objetivo ajustar um modelo de regressão linear múltiplo com o intuito de investigar a influência de determinadas características (medidas) associadas a características de pessoas a característica `gasto médio em crédito` (`“balance”`).

Neste contexto a regressão será realizada sobre a base de dados `Credit`, introduzida no livro @James2013, que contém características relacionadas a pessoas que possuem crédito em contas de banco, por exemplo: renda, limite de crédito, nível de educação e idade.

Utilizaremos o nível de significancia de 10% para toda análise.

# Os dados

É possível baixar os dados do [UCI Machine Learning Repository -- Iris Data Set](https://archive.ics.uci.edu/dataset/53/iris), mas a biblioteca `ISLR` do *R* já os contém. Apenas carregando a biblioteca, um data frame chamado `credit` fica disponibilizado e poderá ser usado imediatamente. Vejamos em seguida.

```{r}
library(dplyr)
library(ISLR)

glimpse(Credit) 
```

Visualizando rapidamente a estrutura da base de dados, observamos as seguintes variáveis:

-   `Credit.ID`: Removeremos essa variável dado que não servirá para nossa análise, pois é somente um identificador;
-   `Credit.Income`: Quantitativa Continua, Salário do usuário em milhares de dolares;
-   `Credit.Limit`: Quantitativa Discreta, Llimite do cartão de crédito do usuário;
-   `Credit.Rating`: Quantitativa Discreta, Nível de crédito do usuário;
-   `Credit.Cards`: Quantitativa Discreta, Número de cartões de crédito;
-   `Credit.Age`: Quantitativa Discreta, Idade do usuário;
-   `Credit.Education`: Quantitativa Ordinal, Nível de educação do usuário em anos;
-   `Credit.Student`: Qualitativa Nominal, Se o usuário foi ou não um estudante;
-   `Credit.Married`: Qualitativa Nominal, Se o usuário já se casou;
-   `Credit.Ethnicity`: Qualitativa Nominal, Indicador da etnia autointitulada pelo usuário;
-   `Credit.Balance`: Variavel resposta de estudo, Qual o gasto médio do cartão de crédito do usuário;

## Análise exploratória dos dados

```{r}
library(skimr)

dados <- Credit %>% select(-ID)
dados <- dados <- dados %>%
  select(Balance, everything())

skim(dados)

dadosNum <- select(dados, -c(Gender, Student, Married, Ethnicity))
```

### Comentários:

Podemos observar que há 400 linhas de dados as quais nenhuma vai ser desconsiderada, dado que observamos também que não há dados NaN. Podemos tabém observar que há 4 variáveis qualitativas e que há mais dados de pessoas sem estudo do que com estudo e mais casadas do que não casadas.

### Análise de correlação {#sec-GGally}

```{r}
library(GGally)

graf1 <- ggpairs(dadosNum, columns = 1:ncol(dadosNum))
graf1

library(ggplot2)
ggsave("Grafico_dispersao_iris.jpeg")

```

#### Comentários

É possível observar que:

1)  A variável dependente `Balance`:

<!-- -->

i.  não apresenta correlação linear significante com a variável `Age` (r= 0.002, 0.1 \< p \< 1);

ii. não apresenta correlação linear significante com a variável `Education` (r= -0.008, 0.1 \< p \< 1);

iii. apresenta correlação linear baixa com a variável `Cards` (r= 0.086, 0.05 \< p \< 0.1);

iv. apresenta correlação linear significante com a variável `Income` (r= 0.464, 0 \< p \< 0.001);

v.  apresenta correlação linear significante com a variável `Limit` (r= 0.862, 0 \< p \< 0.001);

vi. apresenta correlação linear significante com a variável `Rating` (r= 0.864, 0 \< p \< 0.001);

<!-- -->

2)  A variável independente `Income`:

<!-- -->

i.  apresenta correlação linear significativa com a variável *independente* `Limit` (r=-0.792, p \< 0).

Como esta correlação, em valor absoluto é praticamente 0.8, ou seja **pode haver indício** para um posterior **problema de multicolinearidade**.

ii. apresenta correlação linear significativa com a variável *independente* `Rating` (r=-0.791, p \< 0).

Como esta correlação, em valor absoluto é praticamente 0.8, ou seja **pode haver indício** para um posterior **problema de multicolinearidade**.

iii. apresenta correlação linear significativa com a variável *independente* `Age` (r=0.175, p\< 0)

Como esta correlação, em valor absoluto não é superior a 0.9 (ou 0.8) não há indício para um posterior problema de multicolinearidade.

3)  A variável independente `Limit`:

<!-- -->

i.  apresenta correlação linear significativa com a variável *independente* `Rating` (r=0.997, p \< 0).

Como esta correlação, em valor absoluto é superior a 0.9 **há indício** para um posterior **problema de multicolinearidade**. Observa-se, ainda, que tal correlação é do tipo forte e positiva, ou seja, **as medidas** associadas se relacionam de forma **fortemente positiva**.

ii. apresenta correlação linear significativa com a variável *independente* `Age` (r=0.101, p\< 0.01)

Como esta correlação, em valor absoluto não é superior a 0.9 (ou 0.8) não há indício para um posterior problema de multicolinearidade.

<!-- -->

4)  A variável independente `Rating`:

<!-- -->

i.  apresenta correlação linear significativa com a variável *independente* `Age` (r=0.103, p\< 0.01)

Como esta correlação, em valor absoluto não é superior a 0.9 (ou 0.8) não há indício para um posterior problema de multicolinearidade.

<!-- -->

#### Multicolinearidade - Analisando o VIF - Variance Inflation Factor

```{r}
library(car)
modelo1 <- lm(Balance ~ ., data = dadosNum)

vif(modelo1)
```

Como podemos ver, são as variáveis `Limit` e `Rating` apresentam vif maior que 10 e são exatamente elas que também apresentaram forte correlação positiva.

# Ajuste do modelo 1

```{r}
summary(modelo1)
```

\
Ao observar o ajuste do primeiro modelo com o intuito de prever o `Gasto médio em crédito` (`Balance`), tem-se que as variáveis `Income`, `Limit`, `Rating` e `Age` explicam de forma estatísticamente significativa e com um bom ajuste indicado pelo Coeficiente de determinação ajustado (Adjusted R-squared: 0.8764). Entretanto, dois resultados nos chamam a atenção, quais sejam:

1)  O erro padrão da variável `Cards` é extremamente maior que os erros padrões das demais variáveis preditoras;

2)  O erro padrão da variável `Education` é significativamente maior que os erros padrões das demais variáveis preditoras;

3)  A variável `Income` apresenta efeito negativo ao `Balance`, talvez pelo fato de que se há um alto saldo entrando na conta do usuário, não há necessidade de se usar o crédito disponível.

4)  A variável `Age` apresenta efeito negativo ao `Balance`, logo quanto maior a idade, menor o `gasto médio em crédito`.

Resumindo, diante das análises prévias e constatações a partir dos resultados do modelo, identificamos que existe o problema de multicolinearidade de modo que as variáveis preditoras `Limit` e `Rating` não conseguem explicar a variável resposta `Balance` de forma uníssona, pois as mesmas compartilham da mesma informação muito fortemente de modo que elas competem para juntas explicarem/predizerem a variável resposta `Balance`, compromentendo assim, a confiabilidade dos coeficientes estimados e dos valores p.

## Existe multicolinearidade, e agora?

Na presente análise, removeremos a variável explicativa `Limit` dado que observamos que é menos explicativa que a `Rating` no gráfico da @sec-GGally. Vejamos:

\

## Modelo sem `Limit` (modelo2) {#sec-modelo2selecionado}

```{r}
modelo2 <- update(modelo1, ~ . -Limit)

summary(modelo2)

dados <- dados %>% select(-Limit)
```

> Observa-se que; para este modelo ajustado; As variáveis independentes `Income`, `Rating` e `Age` são estatísticamente significativas com a adequação de ajuste do modelo aos dados igual a 87,5% (Adjusted R-squared: 0.8749).

### Vif para o modelo

```{r}
vif(modelo2)
```

> Podemos ver que não há problema de correlação linear entre as variáveis independentes, visto que o vif deu abaixo de 10.

\

# Regressão com variáveis Qualitativas (Dummies/Fictícias/Indicadoras)

Agora, colocaremos novamente as variáveis quantitativas para fazermos as análises com os dados sem problema de multicolinearidade entre as variáveis explicativas.

## Análise de correlação

```{r, fig.width=10, fig.height=10}
dadosGender <- dados %>% select(-c(Student,Married,Ethnicity))

graf2 <- ggpairs(dadosGender, columns = 1:ncol(dadosGender), ggplot2::aes(colour=Gender), progress = FALSE)
print(graf2)
```

Observamos que ...

```{r, fig.width=10, fig.height=10}
dadosStudent <- dados %>% select(-c(Gender,Married,Ethnicity))

graf2 <- ggpairs(dadosStudent, columns = 1:ncol(dadosStudent), ggplot2::aes(colour=Student))
graf2
```

Observamos que ...

```{r, fig.width=10, fig.height=10}
dadosMarried <- dados %>% select(-c(Student,Gender,Ethnicity))

graf2 <- ggpairs(dadosMarried, columns = 1:ncol(dadosMarried), ggplot2::aes(colour=Married))
graf2
```

Observamos que ...

```{r, fig.width=15, fig.height=10}
dadosEthnicity <- dados %>% select(-c(Student,Married,Gender))

graf2 <- ggpairs(dadosEthnicity, columns = 1:ncol(dadosEthnicity), ggplot2::aes(colour=Ethnicity))
graf2
```

Observamos que ...

## Multicolinearidade - Analisando o VIF - Variance Inflation Factor

```{r}
modelo3 <- lm(Balance ~ ., data = dados)

vif(modelo3)
```

Como podemos ver, não há nenhum valor acima de 10, logo, não é notado um problema de multicolinearidade.

## Modelo com variáveis qualitativas

```{r}
summary(modelo3)
```

Observa-se que; para este modelo ajustado; As variáveis independentes Cards, Education, Gender, Married e Ethnicity são estatísticamente insignificativas para a variável resposta Balance, logo, iremos remove-las. Também podemos observar que a variável qualitativa Student é estatisticamente significante para nossa variável resposta.

```{r}
dados <- dados %>% select(-c(Cards, Education, Gender, Married, Ethnicity))

modelo4 <- lm(Balance ~ ., data = dados)
```

# Métodos de seleção de modelos

## Medida AIC

```{r}
AIC(modelo3)

AIC(modelo4)

```

> Comparando-se os dois modelos; observa-se que o modelo com o menor valor de AIC é o modelo 4. Mas, como regra prática, não observa-se uma diferença entre os valores superior a 10 para que haja um indício significativo de real diferença, então podemos escolher o modelo 3 ou o 4.

## Medida BIC

```{r}
BIC(modelo3)

BIC(modelo4)

```

> De maneira contrária ao AIC, podemos observar um valor de BIC significativamente menor para o modelo 4 (diferença maior que 10), logo, será o modelo selecionado.

## Comparação de modelos encaixados (ANOVA) e R-Ajustado

\

```{r}
anova(modelo4, modelo3)
```

TODO (Comentario do resultado da anova)


```{r}
summary(modelo4)
```

Podemos perceber que o R-Ajustado para o modelo 3 e para o modelo 4 deram iguais. Logo, temos que os dois modelos explicam a mesma coisa, então, selecionamos o com menos variáveis (modelo4).

# Modelo selecionado (modelo4)

Diante das análises realizadas até o momento e tendo como objetivos não apenas realizar previsões mas também interpretar de forma prática a relação entre as variáveis; o modelo a ser adotado e a ser **verificado o atendimento dos pressuposto** de um MRLM é o **modelo 4**. Vejamos:

```{r}
plot(modelo4)
```

## Análises dos pressupostos e Comentários

Análises análogas à Regressão Linear Simples.

- residual vs fitted: Foi percebido nos gráficos de residuos e altos indices da não linearidade dos dados além de suspeita de heterocedasticidade. Então, para poder melhorar a predição para além do que foi feito nessa análise, seria necessário a utilização de modelos não lineares e mais robustos.
- QQ plot: o gráfico apresenta "enviesamento para a direita" que mais uma vez traz indicios de não linearidade
- Scale-location: a direção negativa do gráfico dos valores adaptados pelo modelo reafirma as suspeitas de homocedasticidade, além disso os pontos não aparentam estarem espalhados aleatóriamente no entorno da linha do modelo.
- residual vs leverage: nenhum ponto dos cados está presente depois da distancia de cook indicando que nenhum ponto é um outlier influente o suficiente para alterar sozinho de forma significativa o resultado do modelo.
...

# Interpretações do modelo selecionado

Uma maneira automatizada para se relatar os resultados de um modelo é utilizando a função `report` do pacote de mesmo nome.

No relatório a ser entregue, o texto deve estar traduzido e interpretado também em termos práticos, de acordo com os objetivos do problema em estudo.

```{r}
library(report)

report(modelo4)
```

(TODO - Traduzir e dar mais contexto)

# Previsões

Para realizar previsões sobre valores para a variável resposta, recomenda-se o uso de valores para as variáveis explicativas dentro dos respectivos intervalos observados. Daí a importância de um breve resumo sobre os dados observados:

```{r}
summary(dados)

```

Agora, suponha que temos por objetivo prever os valores de `Balance` considerando os seguintes valores para as variáveis explicativas:

```{r}
novas.preditoras <- data.frame(Income=c(21.01, 45.22, 57.47), Rating=c(247.2, 354.9, 437.2), Age=c(41.75, 55.67, 70.0), Student=c("No", "No", "Yes"))
```

## Intervalo de Confiança

```{r}

predict(modelo4, novas.preditoras)

```

comentario(TODO)

## Intervalo de Confiança

```{r}

predict(modelo4, novas.preditoras,
        interval = "confidence")

```

comentario(TODO)

## Intervalo de Predição/Previsão

Um **intervalo de predição** captura a incerteza em torno de um **único valor** não observado na base de dados e não em torno do seu **valor médio/esperado** o qual é obtido pelas variáveis preditoras observadas na base de dados.

```{r}
predict(modelo4, novas.preditoras,
        interval = "prediction")

```

comentario(TODO)

**Interpretações**:

TODO

\

# Conclusão

É importantíssimo que no relatório estatístico haja esta seção para descrever em linhas gerais os resultados obtidos, especialmente em termos de resultados práticos e importantes para a resolução de um problema acadêmico e ou para a revelação(ões) de *insights* para um problema de negócio.
